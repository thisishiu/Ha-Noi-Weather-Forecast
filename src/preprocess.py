import pandas as pd
from sklearn.preprocessing import MinMaxScaler
from pathlib import Path
import numpy as np

def preprocess(input_path="data/hanoi_weather.csv", output_dir="data/processed"):
    print(f"üöÄ Loading {input_path} ...")
    df = pd.read_csv(input_path, parse_dates=["datetime"])
    df = df.dropna(subset=["datetime"]).sort_values(["district", "datetime"]).reset_index(drop=True)

    # === C√°c c·ªôt ƒë·∫∑c tr∆∞ng c·∫ßn d√πng ===
    features = [
        "temperature_2m", "relative_humidity_2m", "dew_point_2m",
        "apparent_temperature", "surface_pressure", "precipitation",
        "cloud_cover", "wind_speed_10m"
    ]

    # === B·ªè c√°c c·ªôt kh√¥ng d√πng ho·∫∑c l·ªói ===
    drop_cols = [
        "snowfall", "shortwave_radiation", "et0_fao_evapotranspiration",
        "lat", "lon"
    ]
    df = df.drop(columns=[c for c in drop_cols if c in df.columns], errors="ignore")

    # === Gi·ªØ l·∫°i c√°c c·ªôt c√≥ trong features + meta ===
    keep_cols = ["datetime", "district"] + [f for f in features if f in df.columns]
    df = df[keep_cols].copy()

    # === Chu·∫©n h√≥a MinMax cho c√°c c·ªôt numeric ===
    scaler = MinMaxScaler()
    numeric_cols = [col for col in features if col in df.columns]
    df[numeric_cols] = scaler.fit_transform(df[numeric_cols])

    # === T·∫°o th∆∞ m·ª•c ƒë·∫ßu ra ===
    Path(output_dir).mkdir(parents=True, exist_ok=True)

    # === L∆∞u file theo t·ª´ng qu·∫≠n ===
    for district, group in df.groupby("district"):
        name = district.replace(" ", "_")
        out_file = Path(output_dir) / f"{name}.csv"
        group.to_csv(out_file, index=False)
        print(f"‚úÖ Saved {name}: {len(group)} rows ‚Üí {out_file}")

    print("‚ú® Preprocessing complete!")
    return df


if __name__ == "__main__":
    preprocess()

